# Helium AI Configuration
# Copy this file to .env and customize for your environment

# Default AI Provider (ollama, openai-compatible, candle, transformerjs)
NEXT_PUBLIC_DEFAULT_AI_PROVIDER=ollama

# Default Model ID for each provider
NEXT_PUBLIC_DEFAULT_OLLAMA_MODEL=qwen2.5-coder:0.5b
NEXT_PUBLIC_DEFAULT_OPENAI_MODEL=gpt-3.5-turbo
NEXT_PUBLIC_DEFAULT_CANDLE_MODEL=embedded-qwen1.5

# Default Endpoints
NEXT_PUBLIC_OLLAMA_ENDPOINT=http://127.0.0.1:11434
NEXT_PUBLIC_OPENAI_COMPATIBLE_ENDPOINT=http://127.0.0.1:8080

# Default Model Parameters
NEXT_PUBLIC_DEFAULT_TEMPERATURE=0.7
NEXT_PUBLIC_DEFAULT_TOP_P=0.9
NEXT_PUBLIC_DEFAULT_MAX_TOKENS=2048

# API Keys (optional, for OpenAI-compatible providers)
# NEXT_PUBLIC_OPENAI_API_KEY=your-api-key-here

# Development Settings
NEXT_PUBLIC_ENABLE_DEBUG_LOGS=false
