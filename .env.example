# RoRo AI Configuration
# Copy this file to .env and customize for your environment

# Default AI Provider for QA Mode (ollama, openai-compatible, candle, transformerjs)
# QA Mode typically works well with lightweight embedded models or local servers
NEXT_PUBLIC_DEFAULT_AI_PROVIDER_QA=candle

# Default AI Provider for Agent Mode (ollama, openai-compatible, candle, transformerjs)
# Agent Mode benefits from more powerful models, often via Ollama or OpenAI-compatible servers
NEXT_PUBLIC_DEFAULT_AI_PROVIDER_AGENT=ollama

# Default Model ID for each provider - QA Mode (smaller, faster models for quick questions)
NEXT_PUBLIC_DEFAULT_OLLAMA_MODEL_QA=qwen2.5-coder:0.5b
NEXT_PUBLIC_DEFAULT_OPENAI_MODEL_QA=gpt-3.5-turbo
NEXT_PUBLIC_DEFAULT_CANDLE_MODEL_QA=embedded-qwen1.5

# Default Model ID for each provider - Agent Mode (larger, more capable models for complex tasks)
NEXT_PUBLIC_DEFAULT_OLLAMA_MODEL_AGENT=qwen2.5-coder:7b
NEXT_PUBLIC_DEFAULT_OPENAI_MODEL_AGENT=gpt-4
NEXT_PUBLIC_DEFAULT_CANDLE_MODEL_AGENT=embedded-qwen1.5

# Default Endpoints
NEXT_PUBLIC_OLLAMA_ENDPOINT=http://127.0.0.1:11434
NEXT_PUBLIC_OPENAI_COMPATIBLE_ENDPOINT=http://127.0.0.1:8080

# Default Model Parameters
NEXT_PUBLIC_DEFAULT_TEMPERATURE=0.7
NEXT_PUBLIC_DEFAULT_TOP_P=0.9
NEXT_PUBLIC_DEFAULT_MAX_TOKENS=2048

# API Keys (optional, for OpenAI-compatible providers)
# NEXT_PUBLIC_OPENAI_API_KEY=your-api-key-here

# Development Settings
NEXT_PUBLIC_ENABLE_DEBUG_LOGS=false
